{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e79ba3-f811-4a8c-8544-8e1147754a9d",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Logistic Regression\n",
    "This simple project focus on identifying either **Tweet** is **Positive** or **Negative**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d2b885-ed75-43ff-973c-4f45d52c3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reload changes from imported files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c849ddb-4bcf-4776-aa01-1494b92ed394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries and packages\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pprint\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e17eb5-aaea-4360-b0f5-ceea3174c5e7",
   "metadata": {},
   "source": [
    "We going to use `tweeter_samples` dataset from `nltk`. This dataset contains subsets of 5,000 positive tweets, 5,000 negative tweets, and the full set of 20,000 tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c760095-8a99-46d2-9a2f-0bc61791a4c5",
   "metadata": {},
   "source": [
    "### Installing dataset and english stopwords\n",
    "```Python\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25aefcaa-636f-40f4-adf5-a358a27ecb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing datasets\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed1de62-b367-4eeb-9906-8e5ade3dd07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative_tweets.json', 'positive_tweets.json', 'tweets.20150430-223406.json']\n"
     ]
    }
   ],
   "source": [
    "# Exploaring the dataset\n",
    "print(twitter_samples.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e399b56-3d9d-43f1-af15-38f5cbefe543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of positive tweets: 5000\n",
      "length of negative tweets: 5000\n"
     ]
    }
   ],
   "source": [
    "# select the set of positive and negative tweets\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "print(f'''length of positive tweets: {len(positive_tweets)}\\nlength of negative tweets: {len(negative_tweets)}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08618ff1-369d-46d0-86aa-a830e853c357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged '\n",
      " 'members in my community this week :)',\n",
      " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 '\n",
      " 'and we will be able to assist you :) Many thanks!',\n",
      " '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing '\n",
      " 'track. When are you in Scotland?!',\n",
      " '@97sides CONGRATS :)',\n",
      " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark '\n",
      " 'on my fb profile :) in 15 days']\n"
     ]
    }
   ],
   "source": [
    "# pretty print top five tweets\n",
    "pprint.pprint(positive_tweets[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aec41b9-0789-406c-893d-e8dc98869cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hopeless for tmr :(',\n",
      " \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 \"\n",
      " 'months :(',\n",
      " '@Hegelbon That heart sliding into the waste basket. :(',\n",
      " '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too',\n",
      " 'Dang starting next week I have \"work\" :(']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(negative_tweets[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f23d3d8-9dab-4ad7-8f51-808fc565fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the datasets into train and test examples\n",
    "train_positive = positive_tweets[:4000]\n",
    "test_positive = positive_tweets[4000:]\n",
    "train_negative = negative_tweets[:4000]\n",
    "test_negative = negative_tweets[4000:]\n",
    "\n",
    "train_x = train_positive + train_negative\n",
    "test_x = test_positive + test_negative\n",
    "\n",
    "train_y = np.append(np.ones((len(train_positive), 1)), np.zeros((len(train_negative), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_positive), 1)), np.zeros((len(test_negative), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce9b285-2545-409a-9f06-02e924b633a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_positive: 4000\n",
      "train_negative: 4000\n",
      "train_x: 8000\n",
      "train_y: 8000\n",
      "test_positive: 1000\n",
      "test_negative: 1000\n",
      "test_x: 2000\n",
      "test_y: 2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shapes = f'''\n",
    "train_positive: {len(train_positive)}\n",
    "train_negative: {len(train_negative)}\n",
    "train_x: {len(train_x)}\n",
    "train_y: {len(train_y)}\n",
    "test_positive: {len(test_positive)}\n",
    "test_negative: {len(test_negative)}\n",
    "test_x: {len(test_x)}\n",
    "test_y: {len(test_y)}\n",
    "'''\n",
    "print(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ae6195-1a9d-47c2-862c-f3c69931055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building frequecy of words in positive and negative tweets\n",
    "freqs = build_freqs(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06986823-5d5c-4207-915b-e4083caffed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "11340\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(type(freqs))\n",
    "print(len(freqs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef317af0-ee11-4334-a62e-d16da46860cd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7ed0ebb-9f75-40e2-b24f-5bedcd663d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.21085308.\n",
      "The resulting vector of weights is [1e-07, 0.00062145, -0.000633]\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# Apply gradient descent\n",
    "J, w = gradientDescent(X, Y, np.zeros((3, 1)), 1e-9, 2000)\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(w)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "910ef86e-1496-487c-adeb-092e31ad1155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 0.522150\n",
      "I am bad -> 0.493630\n",
      "this movie should have been great. -> 0.518388\n",
      "great -> 0.518437\n",
      "great great -> 0.536823\n",
      "great great great -> 0.555110\n",
      "great great great great -> 0.573249\n"
     ]
    }
   ],
   "source": [
    "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
    "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs, w).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3486ef2-83c6-4ba7-8af8-5bfc7c45d8a1",
   "metadata": {},
   "source": [
    "### Testing with user tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b96c7300-515c-47c0-8eb8-d95efe14fa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plot', 'terribl', 'sad', 'end']\n",
      "[[0.47969763]]\n",
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "# Feel free to change the tweet below\n",
    "my_tweet = 'The plot was terrible and I was sad until the ending!'\n",
    "print(process_tweet(my_tweet))\n",
    "y_hat = predict_tweet(my_tweet, freqs, w)\n",
    "print(y_hat)\n",
    "if y_hat > 0.5:\n",
    "    print('Positive sentiment')\n",
    "else: \n",
    "    print('Negative sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b97d0-30b3-4293-bfdd-94e0d528ef19",
   "metadata": {},
   "source": [
    "###  Evaluating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75194961-92f9-4aec-b0c9-233e041c4339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.9955\n"
     ]
    }
   ],
   "source": [
    "tmp_accuracy = test_logistic_regression(test_x, test_y, freqs, w)\n",
    "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d31907-947b-45e5-9c43-ef94554b7cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
